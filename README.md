# Fairness-in-Large-Language-Models

![Fairness in Large Language Models](https://github.com/super-hash/Fairness-in-Large-Language-Models/blob/main/Fairness%20in%20Large%20Language%20Models.png)
## Surveys
+ Fairness in Large Language Models: A Taxonomic Survey, [[arXiv]](https://arxiv.org/abs/2404.01349)
+ Bias and Fairness in Large Language Models: A Survey, [[arXiv]](https://arxiv.org/abs/2309.00770)
+ A survey on fairness in large language models, [[arXiv]](https://arxiv.org/abs/2308.10149)

## Quantifying Bias in LLMs
### Embbedding-based Metrics
+ Semantics derived automatically from language corpora contain human-like biases (WEAT), [[arXiv]](https://arxiv.org/abs/1608.07187)
+ On measuring social biases in sentence encoders (SEAT), [[NAACL]](https://arxiv.org/abs/1903.10561)
+ Detecting emergent intersectional biases: Contextualized word embeddings contain a distribution of human-like biases, [[AAAI]](https://dl.acm.org/doi/abs/10.1145/3461702.3462536)
### Probability-based Metrics

### Generation-based Metrics

## Mitigating Bias in LLMs
### Pre-processing
### In-training
### Intra-processing
### Post-processing

## Datasets
